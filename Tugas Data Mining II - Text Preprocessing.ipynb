{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68cd80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b7ce9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>from_user</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>time</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>from_user_id_str</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1357116635094474754</td>\n",
       "      <td>pelindo3</td>\n",
       "      <td>Pelindo III Peduli Banjir Sekotong\\n-\\nHalo #P...</td>\n",
       "      <td>Wed Feb 03 23:59:54 +0000 2021</td>\n",
       "      <td>2021-02-03 23:59:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81799468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11582.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1357116624285749253</td>\n",
       "      <td>hye_bye_99</td>\n",
       "      <td>RT @luqmanlong: Bab orang sentuh pangkat Datuk...</td>\n",
       "      <td>Wed Feb 03 23:59:51 +0000 2021</td>\n",
       "      <td>2021-02-03 23:59:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1741183075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Johor Bahru, Johor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1357116610280968194</td>\n",
       "      <td>anwar_muhmmd</td>\n",
       "      <td>@pln_123 Sudah min, banjir juga ws surut</td>\n",
       "      <td>Wed Feb 03 23:59:48 +0000 2021</td>\n",
       "      <td>2021-02-03 23:59:48</td>\n",
       "      <td>5.585161e+08</td>\n",
       "      <td>pln_123</td>\n",
       "      <td>1088076279331512320</td>\n",
       "      <td>1.357097e+18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Kota Probolinggo, Jawa Timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1357116566752530432</td>\n",
       "      <td>petabencana</td>\n",
       "      <td>@BangJac63679229 Halo, saya Bencana Bot. Untuk...</td>\n",
       "      <td>Wed Feb 03 23:59:38 +0000 2021</td>\n",
       "      <td>2021-02-03 23:59:38</td>\n",
       "      <td>1.345356e+18</td>\n",
       "      <td>BangJac63679229</td>\n",
       "      <td>2276880895</td>\n",
       "      <td>1.357117e+18</td>\n",
       "      <td>122065.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1357116555188871168</td>\n",
       "      <td>milokasaka</td>\n",
       "      <td>RT @hxppypom_: Tweet macam ni selalu tak viral...</td>\n",
       "      <td>Wed Feb 03 23:59:35 +0000 2021</td>\n",
       "      <td>2021-02-03 23:59:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1036594916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Mirul's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str     from_user  \\\n",
       "0  1357116635094474754      pelindo3   \n",
       "1  1357116624285749253    hye_bye_99   \n",
       "2  1357116610280968194  anwar_muhmmd   \n",
       "3  1357116566752530432   petabencana   \n",
       "4  1357116555188871168    milokasaka   \n",
       "\n",
       "                                                text  \\\n",
       "0  Pelindo III Peduli Banjir Sekotong\\n-\\nHalo #P...   \n",
       "1  RT @luqmanlong: Bab orang sentuh pangkat Datuk...   \n",
       "2           @pln_123 Sudah min, banjir juga ws surut   \n",
       "3  @BangJac63679229 Halo, saya Bencana Bot. Untuk...   \n",
       "4  RT @hxppypom_: Tweet macam ni selalu tak viral...   \n",
       "\n",
       "                       created_at                time  \\\n",
       "0  Wed Feb 03 23:59:54 +0000 2021 2021-02-03 23:59:54   \n",
       "1  Wed Feb 03 23:59:51 +0000 2021 2021-02-03 23:59:51   \n",
       "2  Wed Feb 03 23:59:48 +0000 2021 2021-02-03 23:59:48   \n",
       "3  Wed Feb 03 23:59:38 +0000 2021 2021-02-03 23:59:38   \n",
       "4  Wed Feb 03 23:59:35 +0000 2021 2021-02-03 23:59:35   \n",
       "\n",
       "   in_reply_to_user_id_str in_reply_to_screen_name     from_user_id_str  \\\n",
       "0                      NaN                     NaN             81799468   \n",
       "1                      NaN                     NaN           1741183075   \n",
       "2             5.585161e+08                 pln_123  1088076279331512320   \n",
       "3             1.345356e+18         BangJac63679229           2276880895   \n",
       "4                      NaN                     NaN           1036594916   \n",
       "\n",
       "   in_reply_to_status_id_str  user_followers_count  user_friends_count  \\\n",
       "0                        NaN               11582.0               344.0   \n",
       "1                        NaN                  90.0               184.0   \n",
       "2               1.357097e+18                   1.0                52.0   \n",
       "3               1.357117e+18              122065.0               311.0   \n",
       "4                        NaN                 277.0               297.0   \n",
       "\n",
       "                  user_location  \n",
       "0                     Indonesia  \n",
       "1            Johor Bahru, Johor  \n",
       "2  Kota Probolinggo, Jawa Timur  \n",
       "3                     Indonesia  \n",
       "4                       Mirul's  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('tweet_banjir.xlsx', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c356944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lwr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pelindo iii peduli banjir sekotong\\n-\\nhalo #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @luqmanlong: bab orang sentuh pangkat datuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@pln_123 sudah min, banjir juga ws surut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@bangjac63679229 halo, saya bencana bot. untuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @hxppypom_: tweet macam ni selalu tak viral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>@alfahrifamily halo, saya bencana bot. untuk m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>rt @itsmirah__: @cacatcintayet @k31019_ kita s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>rt @kartelego: ayo habiskan hutanmu, entah pak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>sedih deh ketika banjir gini, seketika mikir k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>banjir astaga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2938 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    lwr\n",
       "0     pelindo iii peduli banjir sekotong\\n-\\nhalo #p...\n",
       "1     rt @luqmanlong: bab orang sentuh pangkat datuk...\n",
       "2              @pln_123 sudah min, banjir juga ws surut\n",
       "3     @bangjac63679229 halo, saya bencana bot. untuk...\n",
       "4     rt @hxppypom_: tweet macam ni selalu tak viral...\n",
       "...                                                 ...\n",
       "2933  @alfahrifamily halo, saya bencana bot. untuk m...\n",
       "2934  rt @itsmirah__: @cacatcintayet @k31019_ kita s...\n",
       "2935  rt @kartelego: ayo habiskan hutanmu, entah pak...\n",
       "2936  sedih deh ketika banjir gini, seketika mikir k...\n",
       "2937                                      banjir astaga\n",
       "\n",
       "[2938 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_lower(lwr):\n",
    "    lwr = lwr.lower()\n",
    "    return lwr\n",
    "\n",
    "df['lwr'] = df['text'].apply(clean_lower)\n",
    "casefolding = pd.DataFrame(df['lwr'])\n",
    "casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf3fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pelindo iii peduli banjir sekotong   halo  por...\n",
       "1       rt  luqmanlong  bab orang sentuh pangkat datuk...\n",
       "2                  pln 123 sudah min banjir juga ws surut\n",
       "3        bangjac63679229 halo saya bencana bot  untuk ...\n",
       "4       rt  hxppypom   tweet macam ni selalu tak viral...\n",
       "                              ...                        \n",
       "2933     alfahrifamily halo saya bencana bot  untuk me...\n",
       "2934    rt  itsmirah     cacatcintayet  k31019  kita s...\n",
       "2935    rt  kartelego  ayo habiskan hutanmu entah paka...\n",
       "2936    sedih deh ketika banjir gini seketika mikir ke...\n",
       "2937                                        banjir astaga\n",
       "Name: clean_punct, Length: 2938, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Puncutuation\n",
    "clean_spcl = re.compile('[/(){}\\[\\]\\|,;]')\n",
    "clean_symbol = re.compile('[^0-9a-z]')\n",
    "def clean_punct(text):\n",
    "    text = clean_spcl.sub('', text)\n",
    "    text = clean_symbol.sub(' ', text)\n",
    "    return text# Buat kolom tambahan untuk data description yang telah diremovepunctuation   \n",
    "df['clean_punct'] = df['lwr'].apply(clean_punct)\n",
    "df['clean_punct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a389d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pelindo iii peduli banjir sekotong halo portiz...\n",
       "1       rt luqmanlong bab orang sentuh pangkat datuk t...\n",
       "2                  pln 123 sudah min banjir juga ws surut\n",
       "3       bangjac63679229 halo saya bencana bot untuk me...\n",
       "4       rt hxppypom tweet macam ni selalu tak viral ba...\n",
       "                              ...                        \n",
       "2933    alfahrifamily halo saya bencana bot untuk mela...\n",
       "2934    rt itsmirah cacatcintayet k31019 kita still ad...\n",
       "2935    rt kartelego ayo habiskan hutanmu entah pakai ...\n",
       "2936    sedih deh ketika banjir gini seketika mikir ke...\n",
       "2937                                        banjir astaga\n",
       "Name: clean_double_ws, Length: 2938, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _normalize_whitespace(text):\n",
    "    corrected = str(text)\n",
    "    corrected = re.sub(r\"//t\",r\"\\t\", corrected)\n",
    "    corrected = re.sub(r\"( )\\1+\",r\"\\1\", corrected)\n",
    "    corrected = re.sub(r\"(\\n)\\1+\",r\"\\1\", corrected)\n",
    "    corrected = re.sub(r\"(\\r)\\1+\",r\"\\1\", corrected)\n",
    "    corrected = re.sub(r\"(\\t)\\1+\",r\"\\1\", corrected)\n",
    "    return corrected.strip(\" \")\n",
    "df['clean_double_ws'] = df['clean_punct'].apply(_normalize_whitespace)\n",
    "df['clean_double_ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc292c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pelindo iii peduli banjir sekotong halo portiz...\n",
       "1       rt luqmanlong bab orang sentuh pangkat datuk t...\n",
       "2                             pln 123 min banjir ws surut\n",
       "3       bangjac63679229 halo bencana bot melaporkan ba...\n",
       "4       rt hxppypom tweet ni viral dah menteri agama t...\n",
       "                              ...                        \n",
       "2933    alfahrifamily halo bencana bot melaporkan banj...\n",
       "2934    rt itsmirah cacatcintayet k31019 still ydpa be...\n",
       "2935    rt kartelego ayo habiskan hutanmu pakai alasan...\n",
       "2936    sedih deh banjir gini mikir keras berangkat ke...\n",
       "2937                                        banjir astaga\n",
       "Name: clean_sw, Length: 2938, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean stopwords\n",
    "stopword = set(stopwords.words('indonesian'))\n",
    "def clean_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split() if word not in stopword) # hapus stopword dari kolom deskripsi\n",
    "    return text# Buat kolom tambahan untuk data description yang telah distopwordsremoval   \n",
    "df['clean_sw'] = df['clean_double_ws'].apply(clean_stopwords)\n",
    "df['clean_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc46e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-395a98420e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_stemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sudah_bersih'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_sw'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sudah_bersih'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelegatedStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_plural_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_singular_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_plural\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;34m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisitor_provider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#step 1 - 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_stemming_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#step 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mstart_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#step 2, 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_suffixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mremove_suffixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_suffixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept_visitors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffix_visitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36maccept_visitors\u001b[1;34m(self, visitors)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvisitor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvisitors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_is_stopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "df['sudah_bersih'] = df['clean_sw'].apply(stemmer.stem)\n",
    "df['sudah_bersih']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12a2ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topik', 'di', 'wag', 'keluarga', 'masih', 'banjir', 'aja']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization=pd.DataFrame(df['sudah_bersih'])\n",
    "token=nltk.tokenize.WhitespaceTokenizer().tokenize(lemmatization['text'][100])\n",
    "token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
